# See https://aka.ms/yaml

trigger:
  - master
  - v*.*.x
pr:
  - master
  - v*.*.x

stages:
  - stage: Build
    jobs:
      - job: build
        strategy:
          maxParallel: 1
          matrix:
            spark-2.4:
              profile_version: "2.4"
              spark_version: "2.4.5"
            spark-3.0:
              profile_version: "3.0"
              spark_version: "3.0.1"
        pool:
          name: MLNX
          demands: Maven
        steps:
          - task: Maven@3
            displayName:  build
            inputs:
              javaHomeOption: "path"
              jdkDirectory: "/hpc/local/oss/java/jdk/"
              jdkVersionOption: "1.8"
              mavenVersionSelection: "Path"
              mavenPath: "/hpc/local/oss/apache-maven-3.3.9"
              mavenSetM2Home: true
              publishJUnitResults: false
              goals: "package"
              options: "-B  -Dmaven.repo.local=$(System.DefaultWorkingDirectory)/target/.deps -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn -Pspark-$(profile_version)"
          - bash: |
              set -xeE
              module load tools/spark-$(spark_version) hpcx-gcc
              source buildlib/test.sh

              if [[ $(get_rdma_device_iface) != "" ]]
              then
                export SPARK_UCX_JAR=$(System.DefaultWorkingDirectory)/target/spark-ucx-1.0-for-spark-$(profile_version)-jar-with-dependencies.jar
                export SPARK_LOCAL_DIRS=$(System.DefaultWorkingDirectory)/target/spark
                export SPARK_VERSION=$(spark_version)
                export UCX_LIB=$HPCX_UCX_DIR/lib
                cd $(System.DefaultWorkingDirectory)/target/
                run_tests
              else
                echo ##vso[task.complete result=Skipped;]No IB devices found
              fi
            displayName: Run spark tests
